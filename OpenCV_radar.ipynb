{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d38937e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "### **Ejercicios**\n",
    "\n",
    "1. Lee y visualiza el vídeo `tra╠üfico01.mp4`.\n",
    "2. Promedia las imágenes del vídeo para obtener un fondo sin coches.\n",
    "3. Resta el fondo a cada imagen del vídeo.\n",
    "4. Umbraliza la imagen resultante para quedarte únicamente con las zonas donde hay diferencias significativas en el valor de los píxeles.\n",
    "4. Detecta los blobs que correspondan a coches, ten en cuenta que los coches son más grandes que el ruido."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "05a61e47",
   "metadata": {},
   "outputs": [],
   "source": [
    "#apartado 1.1\n",
    "import cv2\n",
    "\n",
    "video = 'tra╠üfico01.mp4'  #ruta del video\n",
    "cap = cv2.VideoCapture(video)  #lee video\n",
    "\n",
    "#lee todos los frames\n",
    "while cap.isOpened():\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        break\n",
    "    cv2.imshow('Video', frame)\n",
    "    if cv2.waitKey(20) & 0xFF == ord('q'): #muestra vídeo entero frame a frame\n",
    "        break\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d6fa7ed2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#apartado 1.2\n",
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "video = 'tra╠üfico01.mp4'\n",
    "cap = cv2.VideoCapture(video)\n",
    "\n",
    "frame_count = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))  #nº total frames\n",
    "ret, frame = cap.read()  #lee primer frame, saber tamaño\n",
    "if not ret or frame is None or frame_count == 0:\n",
    "    print(\"Error, no se puede leer el vídeo.\")\n",
    "    cap.release()\n",
    "    exit()\n",
    "\n",
    "avg_frame = np.zeros_like(frame, dtype=np.float32)  #crea imagen para acumular suma, tipo flotante para no problema\n",
    "cap.set(cv2.CAP_PROP_POS_FRAMES, 0)  #volvemos primer frame\n",
    "\n",
    "valid_frames = 0\n",
    "for i in range(frame_count):\n",
    "    ret, frame = cap.read()\n",
    "    if not ret or frame is None:\n",
    "        continue\n",
    "    avg_frame += frame.astype(np.float32)\n",
    "    valid_frames += 1\n",
    "\n",
    "if valid_frames == 0:\n",
    "    print(\"Error, no se puede leer ningún frame.\")\n",
    "    cap.release()\n",
    "    exit()\n",
    "\n",
    "avg_frame /= valid_frames\n",
    "avg_frame = np.nan_to_num(avg_frame)\n",
    "background = avg_frame.astype(np.uint8)\n",
    "\n",
    "cv2.imshow('background promedia', background)\n",
    "cv2.imwrite('background.png', background)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "dc4ba59a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#apartado 1.3\n",
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "video = 'tra╠üfico01.mp4'\n",
    "background = cv2.imread('background.png')  # Imagen del fondo promedio\n",
    "\n",
    "if background is None:\n",
    "    print(\"Error: No se pudo cargar 'background.png'.\")\n",
    "    exit()\n",
    "\n",
    "cap = cv2.VideoCapture(video)\n",
    "\n",
    "while cap.isOpened():\n",
    "    ret, frame = cap.read()\n",
    "    if not ret or frame is None:\n",
    "        break\n",
    "    # Resta el fondo al frame actual\n",
    "    diff = cv2.absdiff(frame, background)\n",
    "    # Muestra el resultado\n",
    "    cv2.imshow('Resta del fondo', diff)\n",
    "    if cv2.waitKey(30) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ca361275",
   "metadata": {},
   "outputs": [],
   "source": [
    "#apartado 1.4\n",
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "video = 'tra╠üfico01.mp4'\n",
    "background = cv2.imread('background.png')\n",
    "\n",
    "if background is None:\n",
    "    print(\"Error: No se pudo cargar 'background.png'.\")\n",
    "    exit()\n",
    "\n",
    "cap = cv2.VideoCapture(video)\n",
    "\n",
    "T = 50  # Ajusta este valor para definir qué es una diferencia significativa\n",
    "\n",
    "while cap.isOpened():\n",
    "    ret, frame = cap.read()\n",
    "    if not ret or frame is None:\n",
    "        break\n",
    "    diff = cv2.absdiff(frame, background)\n",
    "    diff_gray = cv2.cvtColor(diff, cv2.COLOR_BGR2GRAY)\n",
    "    _, diff_bin = cv2.threshold(diff_gray, T, 255, cv2.THRESH_BINARY)\n",
    "    cv2.imshow('Diferencias significativas', diff_bin)\n",
    "    if cv2.waitKey(30) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6289700a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Coches únicos detectados en el vídeo: 5\n"
     ]
    }
   ],
   "source": [
    "# VEHICULOS DETECTADOS 1.5 (mínimo 5)\n",
    "\n",
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "video = 'tra╠üfico01.mp4'\n",
    "background = cv2.imread('background.png')\n",
    "\n",
    "if background is None:\n",
    "    print(\"Error: No se pudo cargar 'background.png'.\")\n",
    "    exit()\n",
    "\n",
    "cap = cv2.VideoCapture(video)\n",
    "\n",
    "T = 50\n",
    "\n",
    "# Lee el primer frame para obtener tamaño\n",
    "ret, frame = cap.read()\n",
    "if not ret or frame is None:\n",
    "    print(\"Error: No se pudo leer el primer frame.\")\n",
    "    exit()\n",
    "\n",
    "height, width = frame.shape[:2]\n",
    "rect_width = 60\n",
    "rect_height = 100\n",
    "top_left_x = (width - rect_width) - 1350\n",
    "top_left_y = (height - rect_height) // 2\n",
    "\n",
    "area_pts = np.array([\n",
    "    [top_left_x, top_left_y],\n",
    "    [top_left_x + rect_width, top_left_y],\n",
    "    [top_left_x + rect_width, top_left_y + rect_height],\n",
    "    [top_left_x, top_left_y + rect_height]\n",
    "])\n",
    "\n",
    "class Coche:\n",
    "    def __init__(self, x, y, w, h, area, id):\n",
    "        self.x = x\n",
    "        self.y = y\n",
    "        self.w = w\n",
    "        self.h = h\n",
    "        self.area = area\n",
    "        self.id = id\n",
    "        self.frames_seen = 1\n",
    "        self.updated = True\n",
    "\n",
    "    def centroide(self):\n",
    "        # Retorna el centro del bounding box\n",
    "        return (self.x + self.w // 2, self.y + self.h // 2)\n",
    "\n",
    "coches_unicos = []\n",
    "proximo_id = 1  # ID incremental de coche\n",
    "\n",
    "# Regresamos al primer frame del video\n",
    "cap.set(cv2.CAP_PROP_POS_FRAMES, 0)\n",
    "DISTANCIA_MAX = 50  # Max distancia en píxeles para considerar \"el mismo coche\"\n",
    "\n",
    "while cap.isOpened():\n",
    "    ret, frame = cap.read()\n",
    "    if not ret or frame is None:\n",
    "        break\n",
    "\n",
    "    diff = cv2.absdiff(frame, background)\n",
    "    diff_gray = cv2.cvtColor(diff, cv2.COLOR_BGR2GRAY)\n",
    "    _, diff_bin = cv2.threshold(diff_gray, T, 255, cv2.THRESH_BINARY)\n",
    "    mask = np.zeros_like(diff_bin)\n",
    "    cv2.fillPoly(mask, [area_pts], 255)\n",
    "    diff_bin_carril = cv2.bitwise_and(diff_bin, mask)\n",
    "    contours, _ = cv2.findContours(diff_bin_carril, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "\n",
    "    detectados = []\n",
    "\n",
    "    for contour in contours:\n",
    "        area = cv2.contourArea(contour)\n",
    "        if area > 500:\n",
    "            x, y, w, h = cv2.boundingRect(contour)\n",
    "            detectados.append((x, y, w, h, area))\n",
    "\n",
    "    # Marcar todos los coches como NO actualizados\n",
    "    for coche in coches_unicos:\n",
    "        coche.updated = False\n",
    "\n",
    "    # Para cada detección, buscar el coche anterior más cercano (tracking simple por centroide)\n",
    "    for x, y, w, h, area in detectados:\n",
    "        c_actual = (x + w // 2, y + h // 2)\n",
    "        min_dist = float('inf')\n",
    "        coche_match = None\n",
    "        for coche in coches_unicos:\n",
    "            c_anterior = coche.centroide()\n",
    "            dist = np.hypot(c_actual[0] - c_anterior[0], c_actual[1] - c_anterior[1])\n",
    "            if dist < min_dist and dist < DISTANCIA_MAX:\n",
    "                min_dist = dist\n",
    "                coche_match = coche\n",
    "        if coche_match is not None:\n",
    "            # Actualiza el coche existente\n",
    "            coche_match.x = x\n",
    "            coche_match.y = y\n",
    "            coche_match.w = w\n",
    "            coche_match.h = h\n",
    "            coche_match.area = area\n",
    "            coche_match.frames_seen += 1\n",
    "            coche_match.updated = True\n",
    "            coche_id = coche_match.id\n",
    "        else:\n",
    "            # Coche NUEVO\n",
    "            nuevo_coche = Coche(x, y, w, h, area, proximo_id)\n",
    "            coches_unicos.append(nuevo_coche)\n",
    "            proximo_id += 1\n",
    "            coche_id = nuevo_coche.id\n",
    "        # Dibuja el bounding box con el ID\n",
    "        cv2.rectangle(frame, (x, y), (x + w, y + h), (0, 255, 0), 2)\n",
    "        cv2.putText(frame, f'ID:{coche_id}', (x, y - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 255, 255), 2)\n",
    "\n",
    "    # Puedes eliminar coches que llevan mucho sin aparecer, aquí queremos mantener el historial\n",
    "\n",
    "    cv2.putText(frame, f'Contador coches: {len(coches_unicos)}', (10, 30), cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 0, 255), 2)\n",
    "    cv2.polylines(frame, [area_pts], isClosed=True, color=(255, 0, 0), thickness=2)\n",
    "    cv2.imshow('Video con detección de coches únicos', frame)\n",
    "    cv2.imshow('Diferencias significativas', diff_bin)\n",
    "\n",
    "    if cv2.waitKey(30) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n",
    "\n",
    "print(f'Coches únicos detectados en el vídeo: {len(coches_unicos)}')\n",
    "\n",
    "\n",
    "# Liberar recursos\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04fd41e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Coches únicos detectados en el vídeo: 77\n",
      "Via 1 - Coches detectados: 8\n",
      "Via 2 - Coches detectados: 5\n",
      "Via 3 - Coches detectados: 5\n",
      "Via 4 - Coches detectados: 27\n",
      "Via 5 - Coches detectados: 18\n",
      "Via 6 - Coches detectados: 14\n"
     ]
    }
   ],
   "source": [
    "# resto de ejercicios\n",
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "video = 'tra╠üfico01.mp4'\n",
    "background = cv2.imread('background.png')\n",
    "\n",
    "if background is None:\n",
    "    print(\"Error: No se pudo cargar 'background.png'.\")\n",
    "    exit()\n",
    "\n",
    "cap = cv2.VideoCapture(video)\n",
    "\n",
    "T = 50                   # umbral para binarizar la diferencia\n",
    "AREA_MINIMA = 100        # área mínima de contorno para considerar detección\n",
    "AREA_MAX = 15000         # área máxima de contorno para considerar detección\n",
    "DISTANCIA_MAX = 78       # distancia máxima para considerar \"el mismo coche\"\n",
    "MAX_FRAMES_PERDIDO = 10  # nº máximo de frames sin ver un coche antes de borrarlo\n",
    "\n",
    "# Lee el primer frame para obtener tamaño\n",
    "ret, frame = cap.read()\n",
    "if not ret or frame is None:\n",
    "    print(\"Error: No se pudo leer el primer frame.\")\n",
    "    exit()\n",
    "\n",
    "height, width = frame.shape[:2]\n",
    "\n",
    "# configuración para cada vía \n",
    "widths  = [60, 70, 70, 200, 200, 100]     # ancho de las vías\n",
    "heights = [35, 100, 100, 100, 90, 70]     # alturas \n",
    "gaps    = [70, 50, 350, -20, -50]         # gaps entre vías (distancia de via a via)\n",
    "y_offsets = [-250, 70, 0, 150, 30, -135]  # offsets verticales por vía (ajusta para poner más arriba o más abajo)\n",
    "\n",
    "USE_EXPLICIT_VIAS = False\n",
    "vias_explicit = [] \n",
    "\n",
    "# via que esta más a la izquierda\n",
    "EXTRA_LEFT = 250  # píxeles para mover la primera vía aún más a la izquierda\n",
    "first_rect_width = widths[0] if len(widths) > 0 else 60\n",
    "base_top_left_x = (width - first_rect_width) - 1350 - EXTRA_LEFT\n",
    "\n",
    "\n",
    "# Construimos varias áreas con tamaños, gaps y offsets verticales distintos\n",
    "area_pts_list = []\n",
    "\n",
    "if USE_EXPLICIT_VIAS and len(vias_explicit) > 0:\n",
    "    for (x, y, w, h) in vias_explicit:\n",
    "        x0 = max(0, min(int(x), width-1))\n",
    "        y0 = max(0, min(int(y), height-1))\n",
    "        x1 = min(width-1, x0 + int(w))\n",
    "        y1 = min(height-1, y0 + int(h))\n",
    "        area_pts = np.array([[x0,y0],[x1,y0],[x1,y1],[x0,y1]])\n",
    "        area_pts_list.append(area_pts)\n",
    "else:\n",
    "    num_vias = len(widths)  # longitud determina NUM_VIAS\n",
    "\n",
    "    # Asegurar que heights, gaps y y_offsets tengan la longitud necesaria\n",
    "    if len(heights) < num_vias:\n",
    "        heights = heights + [heights[-1]] * (num_vias - len(heights))\n",
    "    if len(gaps) < max(0, num_vias-1):\n",
    "        gaps = gaps + [0] * (max(0, num_vias-1) - len(gaps))\n",
    "    if len(y_offsets) < num_vias:\n",
    "        y_offsets = y_offsets + [0] * (num_vias - len(y_offsets))\n",
    "\n",
    "    tlx = base_top_left_x\n",
    "    for i in range(num_vias):\n",
    "        wv = int(widths[i])\n",
    "        hv = int(heights[i])\n",
    "        # centrar verticalmente cada vía según su altura y aplicar offset vertical específico\n",
    "        tly = (height - hv) // 2 + int(y_offsets[i])\n",
    "        # Clamp para no salir del frame\n",
    "        x0 = max(0, min(tlx, width-1))\n",
    "        y0 = max(0, min(tly, height-1))\n",
    "        x1 = min(width-1, x0 + wv)\n",
    "        y1 = min(height-1, y0 + hv)\n",
    "        area_pts = np.array([\n",
    "            [x0, y0],\n",
    "            [x1, y0],\n",
    "            [x1, y1],\n",
    "            [x0, y1]\n",
    "        ])\n",
    "        area_pts_list.append(area_pts)\n",
    "        # mover X acumulativo: ancho de esta vía + gap (cuando existe)\n",
    "        gap = gaps[i] if i < len(gaps) else 0\n",
    "        tlx = tlx + wv + gap\n",
    "\n",
    "# inicialización de los contadores por vía\n",
    "counters_vias = [0 for _ in range(len(area_pts_list))]\n",
    "\n",
    "class Coche:\n",
    "    def __init__(self, x, y, w, h, area, id, via_index=None):\n",
    "        self.x = x\n",
    "        self.y = y\n",
    "        self.w = w\n",
    "        self.h = h\n",
    "        self.area = area\n",
    "        self.id = id\n",
    "        self.frames_seen = 1\n",
    "        self.updated = True\n",
    "        self.via_index = via_index  # vía en la que fue detectado inicialmente\n",
    "        self.frames_perdido = 0     # nº de frames seguidos sin ser actualizado\n",
    "\n",
    "    def centroide(self):\n",
    "        # Retorna el centro del bounding box\n",
    "        return (self.x + self.w // 2, self.y + self.h // 2)\n",
    "\n",
    "coches_unicos = []\n",
    "proximo_id = 1        # ID incremental de coche\n",
    "total_coches = 0      # número total de coches distintos creados\n",
    "\n",
    "# volvemos al primer frame del video\n",
    "cap.set(cv2.CAP_PROP_POS_FRAMES, 0)\n",
    "\n",
    "while cap.isOpened():\n",
    "    ret, frame = cap.read()\n",
    "    if not ret or frame is None:\n",
    "        break\n",
    "\n",
    "    diff = cv2.absdiff(frame, background)\n",
    "    diff_gray = cv2.cvtColor(diff, cv2.COLOR_BGR2GRAY)\n",
    "    _, diff_bin = cv2.threshold(diff_gray, T, 255, cv2.THRESH_BINARY)\n",
    "\n",
    "    \n",
    "    detectados = []  # guardamos (x, y, w, h, area, via_index) por detección\n",
    "\n",
    "    # Para cada vía, aplicamos su máscara y extraemos contornos, para evitar duplicados cuando hay solapamiento entre vías, se guardarán los centros ya asignados\n",
    "    centros_asignados = set()\n",
    "    for idx, area_pts in enumerate(area_pts_list):\n",
    "        mask = np.zeros_like(diff_bin)\n",
    "        cv2.fillPoly(mask, [area_pts], 255)\n",
    "        diff_bin_carril = cv2.bitwise_and(diff_bin, mask)\n",
    "        contours, _ = cv2.findContours(diff_bin_carril, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "\n",
    "        for contour in contours:\n",
    "            area = cv2.contourArea(contour)\n",
    "            if AREA_MINIMA <= area <= AREA_MAX:\n",
    "                x, y, wv, hv = cv2.boundingRect(contour)\n",
    "                cX = x + wv//2\n",
    "                cY = y + hv//2\n",
    "                centro_key = (int(cX), int(cY))\n",
    "                # Si ya asignamos una detección con el mismo centro, la saltamos\n",
    "                if centro_key in centros_asignados:\n",
    "                    continue\n",
    "                centros_asignados.add(centro_key)\n",
    "                detectados.append((x, y, wv, hv, area, idx))\n",
    "\n",
    "    # Marcar todos los coches como no actualizados\n",
    "    for coche in coches_unicos:\n",
    "        coche.updated = False\n",
    "\n",
    "    # Para cada detección, buscar el coche anterior más cercano\n",
    "    for x, y, wv, hv, area, via_idx in detectados:\n",
    "        c_actual = (x + wv // 2, y + hv // 2)\n",
    "        min_dist = float('inf')\n",
    "        coche_match = None\n",
    "        for coche in coches_unicos:\n",
    "            c_anterior = coche.centroide()\n",
    "            dist = np.hypot(c_actual[0] - c_anterior[0], c_actual[1] - c_anterior[1])\n",
    "            if dist < min_dist and dist < DISTANCIA_MAX:\n",
    "                min_dist = dist\n",
    "                coche_match = coche\n",
    "\n",
    "        if coche_match is not None:\n",
    "            # se actualiza el coche existente\n",
    "            coche_match.x = x\n",
    "            coche_match.y = y\n",
    "            coche_match.w = wv\n",
    "            coche_match.h = hv\n",
    "            coche_match.area = area\n",
    "            coche_match.frames_seen += 1\n",
    "            coche_match.updated = True\n",
    "            coche_match.frames_perdido = 0\n",
    "            coche_id = coche_match.id\n",
    "            # Si aún no tiene vía asignada, y la detección está en una vía, se le asigna\n",
    "            if coche_match.via_index is None and via_idx is not None:\n",
    "                coche_match.via_index = via_idx\n",
    "                counters_vias[via_idx] += 1\n",
    "        else:\n",
    "            # nuevo coche\n",
    "            nuevo_coche = Coche(x, y, wv, hv, area, proximo_id, via_index=via_idx)\n",
    "            coches_unicos.append(nuevo_coche)\n",
    "            if via_idx is not None:\n",
    "                counters_vias[via_idx] += 1\n",
    "            proximo_id += 1\n",
    "            total_coches += 1        # contamos el coche nuevo como uno distinto\n",
    "            coche_id = nuevo_coche.id\n",
    "\n",
    "        # se dibuja el bounding box con el ID\n",
    "        cv2.rectangle(frame, (x, y), (x + wv, y + hv), (0, 255, 0), 2)\n",
    "        cv2.putText(frame, f'ID:{coche_id}', (x, y - 10),\n",
    "                    cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 255, 255), 2)\n",
    "\n",
    "    # eliminamos lo coches que ya no aparecen\n",
    "    coches_filtrados = []\n",
    "    for coche in coches_unicos:\n",
    "        if coche.updated:\n",
    "            coches_filtrados.append(coche)\n",
    "        else:\n",
    "            coche.frames_perdido += 1\n",
    "            if coche.frames_perdido <= MAX_FRAMES_PERDIDO:\n",
    "                coches_filtrados.append(coche)\n",
    "            # si lo hemos perdido demasiados frames, lo quitamos de la lista\n",
    "    coches_unicos = coches_filtrados\n",
    "\n",
    "    # dibujamos todas las vías y sus contadores\n",
    "    for idx, area_pts in enumerate(area_pts_list):\n",
    "        color = (255, 0, 0)\n",
    "        cv2.polylines(frame, [area_pts], isClosed=True, color=color, thickness=2)\n",
    "        px = int(area_pts[0][0]) + 5\n",
    "        py = int(area_pts[0][1]) - 10\n",
    "        cv2.putText(frame, f'Via {idx+1}: {counters_vias[idx]}', (px, py),\n",
    "                    cv2.FONT_HERSHEY_SIMPLEX, 0.8, (0,0,255), 2)\n",
    "\n",
    "    # usamos total_coches, es decir, coches distintos en lugar de len(coches_unicos)\n",
    "    cv2.putText(frame, f'Contador coches: {total_coches}', (10, 30),\n",
    "                cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 0, 255), 2)\n",
    "\n",
    "    cv2.imshow('Video con detección de coches únicos', frame)\n",
    "    cv2.imshow('Diferencias significativas', diff_bin)\n",
    "\n",
    "    if cv2.waitKey(30) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n",
    "\n",
    "print(f'Coches únicos detectados en el vídeo: {total_coches}')\n",
    "for idx, cnt in enumerate(counters_vias):\n",
    "    print(f'Via {idx+1} - Coches detectados: {cnt}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
